{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "reading all libraries and packages that we need\n",
    "'''\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import os\n",
    "import sys\n",
    "from skimage import io\n",
    "import pandas as pd\n",
    "from skimage.feature import peak_local_max\n",
    "from skimage.morphology import watershed\n",
    "from skimage.segmentation import mark_boundaries\n",
    "from skimage.measure import regionprops, label\n",
    "import SimpleITK as sitk\n",
    "from scipy.ndimage import binary_fill_holes\n",
    "from scipy import ndimage as ndi\n",
    "from skimage.morphology import closing, square, remove_small_objects, binary_erosion, disk, binary_dilation\n",
    "from skimage.segmentation import clear_border\n",
    "from skimage.color import label2rgb\n",
    "import time\n",
    "\n",
    "from skimage.filters import  threshold_otsu, threshold_triangle, gaussian, threshold_local\n",
    "from skimage.morphology import convex_hull_image\n",
    "from skimage.draw import line, polygon\n",
    "import plotly\n",
    "from plotly.offline import plot \n",
    "from scipy.stats import kstest\n",
    "from scipy.stats import ks_2samp\n",
    "import pickle\n",
    "from collections import OrderedDict\n",
    "from collections import Counter\n",
    "from scipy.stats import kstest\n",
    "from scipy.stats import ks_2samp\n",
    "import mrc\n",
    "import plotly.express as px\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prune_and_label_dapi(seg_dapi, debris_size, erosion_radius):\n",
    "    ''' Segments the dapi image.\n",
    "    Ipnuts:\n",
    "    \n",
    "    seg_dapi: 2-dimensional numpy array (segmented image array)\n",
    "    debris_size: size of the debris to be removed (in pixels)\n",
    "    erosion_radius: radius (in pixels) of the disk to be used for binary ersion to separate connected nuclei\n",
    "    \n",
    "    Outputs:\n",
    "    nuclear_mask: segmented nuclei image\n",
    "    nuclear_labels: labled nuclei\n",
    "    \n",
    "    '''\n",
    "    # remove small debris from the segmented imaage\n",
    "    seg_dapi_1 = remove_small_objects(seg_dapi, debris_size)\n",
    "    \n",
    "    seg_dapi_2 = binary_erosion(seg_dapi_1, disk(2))\n",
    "    \n",
    "    # fill the holes in the image\n",
    "    nuclear_mask = ndi.binary_fill_holes(seg_dapi_2)\n",
    "\n",
    "    \n",
    "#     nuclear_mask = remove_small_objects(nuclear_mask, min_area_to_keep_cell)\n",
    "    \n",
    "    # erode the image\n",
    "    eroded_mask = binary_erosion(nuclear_mask, disk(erosion_radius))\n",
    "\n",
    "    distance = ndi.distance_transform_edt(eroded_mask)\n",
    "    local_maxi = peak_local_max(distance, indices=False, footprint=np.ones((1, 1)),\n",
    "                                labels=nuclear_mask)\n",
    "    markers = ndi.label(local_maxi)[0]\n",
    "    nuclear_labels = watershed(-distance, markers, mask=nuclear_mask, connectivity=2)\n",
    "    \n",
    "    return nuclear_mask, nuclear_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def segment_and_label_dapi(dapi_image, debris_size, min_area_to_keep_cell, erosion_radius, block_size = 251):\n",
    "    ''' Segments the dapi image.\n",
    "    Ipnuts:\n",
    "    \n",
    "    dapi_image: 2-dimensional numpy array (image array)\n",
    "    debris_size: size of the debris to be removed (in pixels)\n",
    "    erosion_radius: radius (in pixels) of the disk to be used for binary ersion to separate connected nuclei\n",
    "    \n",
    "    Outputs:\n",
    "    nuclear_mask: segmented nuclei image\n",
    "    nuclear_labels: labled nuclei\n",
    "    \n",
    "    '''\n",
    "#     temp_seg_1 = dapi_image > threshold_otsu(dapi_image)\n",
    "    # locad thresholding to segment the nuclei\n",
    "    adaptive_thresh = threshold_local(dapi_image, block_size = block_size)\n",
    "    seg_dapi = dapi_image > adaptive_thresh\n",
    "    \n",
    "#     seg_dapi = temp_seg_1*temp_seg_2\n",
    "    \n",
    "    # use Otsu method to segment the dapi image\n",
    "#     seg_dapi = dapi_image > threshold_otsu(dapi_image)\n",
    "\n",
    "    # fill the holes in the image\n",
    "    nuclear_mask = ndi.binary_fill_holes(seg_dapi)\n",
    "    \n",
    "    # remove small debris from the segmented imaage\n",
    "    seg_dapi = remove_small_objects(seg_dapi, debris_size)\n",
    "\n",
    "    \n",
    "    \n",
    "    nuclear_mask = remove_small_objects(nuclear_mask, min_area_to_keep_cell)\n",
    "    \n",
    "    # erode the image\n",
    "    eroded_mask = binary_erosion(nuclear_mask, disk(erosion_radius))\n",
    "\n",
    "    distance = ndi.distance_transform_edt(eroded_mask)\n",
    "    local_maxi = peak_local_max(distance, indices=False, footprint=np.ones((1, 1)),\n",
    "                                labels=nuclear_mask)\n",
    "    markers = ndi.label(local_maxi)[0]\n",
    "    nuclear_labels = watershed(-distance, markers, mask=nuclear_mask, connectivity=2)\n",
    "    \n",
    "    return nuclear_mask, nuclear_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def obtain_big_cells(labeled_img, area_thresh, cir_thresh):\n",
    "        ''' Determining the package of the cells as a big cell.\n",
    "    Ipnuts:\n",
    "    \n",
    "    labeled_img: nuclei label from the labling function\n",
    "    area_thresh: maximum size of a nucleus (in pixels) to be considered as a single nucleus\n",
    "    cir_thresh: circularity threshold to see whether it is a single nucleus or multiple nuclei\n",
    "    \n",
    "    Outputs:\n",
    "    big_cells: label of the cells that are satistfying the area AND circularity threshold\n",
    "    \n",
    "    '''\n",
    "    circ = lambda r: (4 * np.pi * r.area) / (r.perimeter * r.perimeter)\n",
    "    big_cells = [(prop.label, prop.area, circ(prop)) for prop in regionprops(labeled_img)\n",
    "                 if prop.area > area_thresh and circ(prop) < cir_thresh]\n",
    "    return big_cells"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_cells(label_rem, image):\n",
    "            ''' Splitting a package of the cells\n",
    "    Ipnuts:\n",
    "    \n",
    "    labeled_rem: label of the object that should be splitted\n",
    "    image: image: 2D labeled image\n",
    "    \n",
    "    Outputs:\n",
    "    labels_rem: label of the cells that are going to split\n",
    "    \n",
    "    '''\n",
    "    \n",
    "    relabels, tmp_img = np.zeros_like(image), np.zeros_like(image)\n",
    "    pts = []\n",
    "    row_cords =[]\n",
    "    col_cords = []\n",
    "    for prop in regionprops(label_rem):\n",
    "        x,y = np.int16(np.round(prop.centroid))\n",
    "        row_cords.append(x)\n",
    "        col_cords.append(y)\n",
    "        pts.extend([x,y])\n",
    "    if len(regionprops(label_rem))>2:\n",
    "        rr, cc = polygon(row_cords, col_cords)\n",
    "    else:\n",
    "        rr, cc = line(pts[0], pts[1], pts[2], pts[3])\n",
    "\n",
    "    tmp_img[rr,cc] =1\n",
    "    tmp_img = binary_dilation(tmp_img, disk(10))\n",
    "    tmp_img = convex_hull_image(tmp_img)\n",
    "    split_img = np.logical_and(image, np.logical_not(tmp_img))\n",
    "    distance_rem = ndi.distance_transform_edt(split_img)\n",
    "    local_maxi_rem = peak_local_max(distance_rem, indices=False, footprint=np.ones((1, 1)),\n",
    "                                labels=image)\n",
    "    markers_rem = label(local_maxi_rem, connectivity=2)\n",
    "    labels_rem = watershed(-distance_rem, markers_rem, mask=image, connectivity=2)\n",
    "    return labels_rem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def obtain_final_labels_after_splitting_big_objects(nuclear_labels, big_cells, \n",
    "                                                    ero_rad, min_rem_area, min_area_to_keep_cell):\n",
    "    '''\n",
    "    Inputs:\n",
    "    nuclear_labels: 2D numpy labeled dapi image\n",
    "    big_cells: label of the big objects\n",
    "    ero_rad: radius of the disk to be used for eroading the region (convex hull - roi)\n",
    "    min_rem_area: removing any object less than of this size (in pixels)\n",
    "    min_area_to_keep_cell: minimum size of an acceptable nucleus (in mpixels)\n",
    "    \n",
    "    Outputs:\n",
    "    final_label: final label of nuecleus after removing small objects and splitting big packages\n",
    "    '''\n",
    "    \n",
    "    relabels = np.zeros_like(nuclear_labels)\n",
    "\n",
    "    for ii, area, cir in big_cells:\n",
    "        image = nuclear_labels==ii\n",
    "        chull = convex_hull_image(image)\n",
    "        rem = np.logical_and(chull, np.logical_not(image))\n",
    "        eroded_rem = binary_erosion(rem, disk(ero_rad))\n",
    "        eroded_rem = remove_small_objects(eroded_rem, min_rem_area)\n",
    "        label_rem = label(eroded_rem)\n",
    "\n",
    "        if np.max(label_rem) >= 2:\n",
    "            relabels = label(relabels + split_cells(label_rem, image))## split cells\n",
    "\n",
    "    assigned_relabels = np.zeros_like(relabels)\n",
    "    for p in regionprops(relabels):\n",
    "        if p.label > 0:\n",
    "            assigned_relabels[np.where(relabels==p.label)] = np.max(nuclear_labels) + p.label\n",
    "\n",
    "    label_img = label(nuclear_labels + assigned_relabels)\n",
    "    label_img = remove_small_objects(label_img, min_area_to_keep_cell)\n",
    "#     final_labels = clear_border(label_img)\n",
    "    final_labels = label_img\n",
    "    return final_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dir(dir_name):\n",
    "    \n",
    "    if not os.path.exists(dir_name):\n",
    "            os.makedirs(dir_name)\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "root_path = r\"D:\\12-January21\\GREB1\\FVWAE2\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "fpaths = [os.path.join(root_path,f) for f in os.listdir(root_path) if f.endswith('.dv')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Default Values\n",
    "sigma = 1\n",
    "erosion_radius = 31\n",
    "debris_size = 100\n",
    "min_area_to_keep_cell = 3000\n",
    "block_size = 651\n",
    "dilation_radius = 100\n",
    "area_thresh =20000# maximum area of the cell to be considered one cell\n",
    "cir_thresh = 0.70\n",
    "ero_rad = 5 # 5 for DV, radius of the disk to be used for eroading the region (convex hull - roi)\n",
    "min_rem_area = 2 # 2 for DV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "seg_dir = os.path.join(root_path, 'Segmentation_erosion_radius_'+ str(erosion_radius)\n",
    "                       + '_min_area_' + str(min_area_to_keep_cell) +'_area_thresh_' + str(area_thresh))\n",
    "\n",
    "if not os.path.exists(seg_dir):\n",
    "    os.makedirs(seg_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating folders for the processed images\n",
    "raw_img_dir = os.path.join(os.path.dirname(seg_dir), 'raw')\n",
    "raw_img_dir_leave_top_bottom = os.path.join(os.path.dirname(seg_dir), 'raw_projected')\n",
    "seg_dapi_dir = os.path.join(os.path.dirname(seg_dir), 'seg_dapi')\n",
    "for dir_name in [raw_img_dir, raw_img_dir_leave_top_bottom, seg_dapi_dir]:\n",
    "    if not os.path.exists(dir_name):\n",
    "        os.makedirs(dir_name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = pd.DataFrame()\n",
    "for fpath in fpaths:\n",
    "    fname = os.path.basename(fpath)\n",
    "    main_fname = ('_').join(fname.split('_')[0:])\n",
    "    if 'wash' in fname:\n",
    "        fname_noext = os.path.splitext(fname)[0]\n",
    "        year, mon_date,  gene,_,_,_,time,field, _, _ =fname_noext.split('_')\n",
    "        # Store features\n",
    "        features = features.append([{'filename': main_fname,\n",
    "                                         'filepath': fpath,\n",
    "                                         'date': ('').join([year,mon_date]),\n",
    "                                         'gene': gene,\n",
    "                                         'time': time,\n",
    "                                         'field' : field,\n",
    "                                          },])\n",
    "    else:\n",
    "        fname_noext = os.path.splitext(fname)[0]\n",
    "        year, mon_date, gene,_,field,_,_ =fname_noext.split('_')\n",
    "        # Store features\n",
    "        features = features.append([{'filename': main_fname,\n",
    "                                         'filepath': fpath,\n",
    "                                         'date': ('').join([year,mon_date]),\n",
    "                                         'gene': gene,\n",
    "                                         'time': '0',\n",
    "                                         'field' : field,\n",
    "                                          },])\n",
    "\n",
    "features = features.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Max projecting the images\n",
    "starting_time = time()\n",
    "\n",
    "for fpath in features['filepath'].unique():\n",
    "    st_time = time()\n",
    "    fname = os.path.splitext(os.path.basename(fpath))[0] + '.tif'\n",
    "    \n",
    "    df = features[features['filepath'] == fpath]\n",
    "    t=df.iloc[0]['time']\n",
    "    f=df.iloc[0]['field']\n",
    "#     print(df['filepath'].values[0])\n",
    "    img_array = mrc.imread(fpath)\n",
    "    DIM=img_array.shape[1]\n",
    "#     print(img_array.shape)\n",
    "\n",
    "    #############################\n",
    "    dapi_image = np.max(img_array[0], axis=0)\n",
    "    io.imsave(os.path.join(raw_img_dir, 'dapi_' + fname), dapi_image)\n",
    "    \n",
    "    dapi_image = np.max(img_array[0, 2:DIM-1], axis=0)\n",
    "    io.imsave(os.path.join(raw_img_dir_leave_top_bottom, 'dapi_' + fname), dapi_image)\n",
    "    \n",
    "    exon_image = np.max(img_array[1], axis=0)\n",
    "    io.imsave(os.path.join(raw_img_dir,'exon_' + fname), exon_image)\n",
    "    \n",
    "    exon_image = np.max(img_array[1, 2:DIM-1], axis=0)\n",
    "    io.imsave(os.path.join(raw_img_dir_leave_top_bottom,'exon_' + fname), exon_image)\n",
    "    \n",
    "    intron_image = np.max(img_array[2], axis=0)\n",
    "    io.imsave(os.path.join(raw_img_dir,'intron_' + fname), intron_image)\n",
    "    \n",
    "    intron_image = np.max(img_array[2, 2:DIM-1], axis=0)\n",
    "    io.imsave(os.path.join(raw_img_dir_leave_top_bottom,'intron_' + fname), intron_image)\n",
    "#     dapi_image =  io.imread(os.path.join(fpath, fname))\n",
    "    # get the nuclear mask and nuclear labels\n",
    "    nuclear_mask, nuclear_labels = segment_and_label_dapi(dapi_image, debris_size, \n",
    "                                                          min_area_to_keep_cell,\n",
    "                                                          erosion_radius,\n",
    "                                                         block_size = block_size)\n",
    "\n",
    "    # get the big cells (to be split if it contains more than 1 cells)\n",
    "    big_cells = obtain_big_cells(nuclear_labels, area_thresh, cir_thresh)\n",
    "\n",
    "    # get the final labels after splitting the big cells\n",
    "    final_labels = obtain_final_labels_after_splitting_big_objects(nuclear_labels, big_cells, ero_rad, \n",
    "                                                min_rem_area, min_area_to_keep_cell)\n",
    "    # nuclei not touching border\n",
    "    non_border_labels = clear_border(final_labels)\n",
    "    nuc_mask = final_labels > 0\n",
    "    marked_dapi = mark_boundaries(dapi_image, non_border_labels, color=(1, 1, 1), outline_color=(1, 1, 1))\n",
    "    io.imsave(os.path.join(seg_dapi_dir, 'dapi_' + fname), np.uint8(marked_dapi*255))\n",
    "print(time() - starting_time )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "newfpaths = [os.path.join(raw_img_dir_leave_top_bottom,f) for f in os.listdir(raw_img_dir_leave_top_bottom) if f.endswith('.tif')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken 366.18459820747375 seconds.\n"
     ]
    }
   ],
   "source": [
    "#Segmenting DAPI channel\n",
    "alpha = 40\n",
    "st_time = time()\n",
    "\n",
    "for fpath in newfpaths:\n",
    "    if 'dapi' in fpath:\n",
    "        \n",
    "    #     print(fpath)\n",
    "        dapi_image = io.imread(fpath)\n",
    "        f = dapi_image\n",
    "        \n",
    "        blurred_f = ndi.gaussian_filter(f, 3)\n",
    "\n",
    "        filter_blurred_f = ndi.gaussian_filter(blurred_f, 1)\n",
    "\n",
    "        \n",
    "        sharpened = blurred_f + alpha * (blurred_f - filter_blurred_f)\n",
    "\n",
    "        filled_seg_dapi = ndi.binary_fill_holes(dapi_image > (0.6*threshold_otsu(dapi_image)))\n",
    "\n",
    "        adaptive_thresh = threshold_local(sharpened, block_size = block_size)\n",
    "\n",
    "        temp_seg_2 = ndi.binary_fill_holes (sharpened > adaptive_thresh)\n",
    "        \n",
    "        seg_dapi = np.logical_and(filled_seg_dapi, temp_seg_2)\n",
    "\n",
    "        fname = os.path.basename(fpath)\n",
    "\n",
    "        io.imsave(os.path.join(seg_dapi_dir, 'seg_' + fname), np.uint8(255*seg_dapi))\n",
    "#         io.imsave(os.path.join(seg_dapi_dir, 'seg_2_' + fname), np.uint8(255*temp_seg_2))\n",
    "        \n",
    "print('Time taken', time()- st_time, 'seconds.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "newfeatures = pd.DataFrame()\n",
    "for fpath in newfpaths:\n",
    "    fname = os.path.basename(fpath)\n",
    "    main_fname = ('_').join(fname.split('_')[1:])\n",
    "    if 'wash' in fname:\n",
    "        fname_noext = os.path.splitext(fname)[0]\n",
    "        wavelength, year, mon_date, _,_,_,_,time,field, _, _ =fname_noext.split('_')\n",
    "        # Store features\n",
    "        newfeatures = newfeatures.append([{'filename': main_fname,\n",
    "                                         'filepath': fpath,\n",
    "                                         'date': ('').join([year,mon_date]),\n",
    "                                         'time': time,\n",
    "                                         'field' : field,\n",
    "                                     'wavelength' : wavelength,\n",
    "                                          },])\n",
    "    else:\n",
    "        fname_noext = os.path.splitext(fname)[0]\n",
    "        wavelength, year, mon_date, _,_, field, _, _ =fname_noext.split('_')\n",
    "        # Store features\n",
    "        newfeatures = newfeatures.append([{'filename': main_fname,\n",
    "                                         'filepath': fpath,\n",
    "                                         'date': ('').join([year,mon_date]),\n",
    "                                         'time': '0',\n",
    "                                         'field' : field,\n",
    "                                     'wavelength' : wavelength,\n",
    "                                          },])\n",
    "\n",
    "newfeatures = newfeatures.reset_index(drop=True)\n",
    "newfeatures = newfeatures.astype({\"field\": int})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = {'15min': 15, '30min':30, '45min': 45, '60min': 60, '75min': 75, '90min':90,'0':0}\n",
    "newfeatures[\"time\"] = newfeatures[\"time\"].map(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "seg_dir = os.path.join(root_path,  'Segmentation_erosion_radius_'+ str(erosion_radius)\n",
    "                       + '_min_area_' + str(min_area_to_keep_cell) +'_area_thresh_' + str(area_thresh))\n",
    "\n",
    "if not os.path.exists(seg_dir):\n",
    "    os.makedirs(seg_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def distance(nuc,intr):\n",
    "    return np.sqrt(np.square(nuc[0]-intr[0])+np.square(nuc[1]-intr[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Using Dictionary for saving the results\n",
    "def create_dicts():\n",
    "    \n",
    "    summary = {}\n",
    "\n",
    "    Mature={}\n",
    "    Mature['inside']={}\n",
    "    Mature['inside_intensities']={}\n",
    "    Mature['outside_mean_intensities']={}\n",
    "    Mature['outside_integ_intensities']={}\n",
    "    Mature['outside_integ_area']={}\n",
    "    Mature['outside']={}\n",
    "    Mature['outside_area']={}\n",
    "    Mature['coloc']={}\n",
    "    threshold={}\n",
    "    \n",
    "    return summary, Mature\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "t =  0 min, f =  1 ,  4865.088057041168 seconds\n",
      "t =  0 min, f =  2 ,  9572.126098632812 seconds\n",
      "t =  0 min, f =  3 ,  16102.116491556168 seconds\n",
      "t =  0 min, f =  4 ,  22191.698852300644 seconds\n",
      "t =  0 min, f =  5 ,  26005.915694236755 seconds\n",
      "t =  15 min, f =  1 ,  30011.216656684875 seconds\n",
      "t =  15 min, f =  2 ,  34432.01913714409 seconds\n",
      "t =  15 min, f =  3 ,  38288.918508291245 seconds\n",
      "t =  15 min, f =  4 ,  41829.76835465431 seconds\n",
      "t =  15 min, f =  5 ,  45325.14707159996 seconds\n",
      "t =  15 min, f =  6 ,  48965.3746650219 seconds\n",
      "t =  15 min, f =  7 ,  53057.42999911308 seconds\n",
      "t =  15 min, f =  8 ,  57659.48322844505 seconds\n",
      "t =  15 min, f =  9 ,  61922.98404383659 seconds\n",
      "t =  15 min, f =  10 ,  68758.90012741089 seconds\n",
      "t =  30 min, f =  1 ,  74562.23758292198 seconds\n",
      "t =  30 min, f =  2 ,  79176.949821949 seconds\n",
      "t =  30 min, f =  3 ,  83552.5816833973 seconds\n",
      "t =  30 min, f =  4 ,  87700.20801973343 seconds\n",
      "t =  30 min, f =  5 ,  92187.76592946053 seconds\n",
      "t =  30 min, f =  6 ,  98352.78194212914 seconds\n",
      "t =  30 min, f =  7 ,  102760.04713773727 seconds\n",
      "t =  30 min, f =  8 ,  106674.52501344681 seconds\n",
      "t =  30 min, f =  9 ,  110864.1561369896 seconds\n",
      "t =  30 min, f =  10 ,  115339.91086173058 seconds\n",
      "t =  45 min, f =  1 ,  121925.48312330246 seconds\n",
      "t =  45 min, f =  2 ,  127287.21826052666 seconds\n",
      "t =  45 min, f =  3 ,  132433.7863960266 seconds\n",
      "t =  45 min, f =  4 ,  139124.56599473953 seconds\n",
      "t =  45 min, f =  5 ,  143831.44751667976 seconds\n",
      "t =  45 min, f =  6 ,  148876.33166360855 seconds\n",
      "t =  45 min, f =  7 ,  152847.64570450783 seconds\n",
      "t =  45 min, f =  8 ,  158210.22860717773 seconds\n",
      "t =  45 min, f =  9 ,  162814.3777692318 seconds\n",
      "t =  45 min, f =  10 ,  169879.99027895927 seconds\n",
      "t =  60 min, f =  1 ,  174139.9821178913 seconds\n",
      "t =  60 min, f =  2 ,  178562.2533671856 seconds\n",
      "t =  60 min, f =  3 ,  183107.0945534706 seconds\n",
      "t =  60 min, f =  4 ,  187196.9698162079 seconds\n",
      "t =  60 min, f =  5 ,  191275.98601222038 seconds\n",
      "t =  60 min, f =  6 ,  195294.2563970089 seconds\n",
      "t =  60 min, f =  7 ,  199501.31755137444 seconds\n",
      "t =  60 min, f =  8 ,  203891.80563235283 seconds\n",
      "t =  60 min, f =  9 ,  208014.0122795105 seconds\n",
      "t =  60 min, f =  10 ,  212122.8498892784 seconds\n",
      "t =  75 min, f =  1 ,  217520.16211390495 seconds\n",
      "t =  75 min, f =  2 ,  221852.66501951218 seconds\n",
      "t =  75 min, f =  3 ,  226744.36446857452 seconds\n",
      "t =  75 min, f =  4 ,  232808.12297201157 seconds\n",
      "t =  75 min, f =  5 ,  238240.7892510891 seconds\n",
      "t =  75 min, f =  6 ,  242625.25648093224 seconds\n",
      "t =  75 min, f =  7 ,  247622.7033009529 seconds\n",
      "t =  75 min, f =  8 ,  252211.7725532055 seconds\n",
      "t =  75 min, f =  9 ,  256442.72080254555 seconds\n",
      "t =  75 min, f =  10 ,  261392.48413395882 seconds\n",
      "t =  90 min, f =  1 ,  266334.79268336296 seconds\n",
      "t =  90 min, f =  2 ,  271195.96185326576 seconds\n",
      "t =  90 min, f =  3 ,  276051.8400530815 seconds\n",
      "t =  90 min, f =  4 ,  280733.4063203335 seconds\n",
      "t =  90 min, f =  5 ,  285251.8642036915 seconds\n",
      "t =  90 min, f =  6 ,  290089.5245742798 seconds\n",
      "t =  90 min, f =  7 ,  293921.90607738495 seconds\n",
      "t =  90 min, f =  8 ,  298537.4077413082 seconds\n",
      "t =  90 min, f =  9 ,  302921.38985967636 seconds\n",
      "t =  90 min, f =  10 ,  307440.7598745823 seconds\n",
      "Elbow room (in %) =  0 , total time taken : 307446.67493391037 seconds\n"
     ]
    }
   ],
   "source": [
    "#Final \n",
    "fpath = raw_img_dir_leave_top_bottom\n",
    "threshold={}\n",
    "threshold['exon']={}\n",
    "threshold['intron']={}\n",
    "temp_dapis = {}\n",
    "temp_introns = {}\n",
    "threshold_df = pd.DataFrame()\n",
    "\n",
    "for ii, room in enumerate(elbow_rooms):\n",
    "    threshold['exon'][room]={}\n",
    "    threshold['intron'][room]={}\n",
    "    starting_time = time()\n",
    "    \n",
    "    append_name = '_' + str(np.abs(room))\n",
    "    \n",
    "    # create dictionaries\n",
    "    summary, Mature = create_dicts()\n",
    "    for file_name in newfeatures['filename'].unique():\n",
    "#         print(file_name)\n",
    "#         t_time = time()\n",
    "        df = newfeatures[newfeatures['filename'] == file_name]\n",
    "        t=df.iloc[0]['time']#str(df.iloc[0]['time']) + \"_\" + df.iloc[0]['treatment']\n",
    "        f=df.iloc[0]['field']\n",
    "#         threshold['exon'][room]['time' +str(t)+'field'+str(f)]=[]\n",
    "#         threshold['intron'][room]['time' +str(t)+'field'+str(f)]=[]\n",
    "        for channel in df['wavelength']:\n",
    "            sdf = df[df['wavelength']==channel]\n",
    "    #         fname = sdf['filename'].get_values()[0]\n",
    "            fname = os.path.basename(list(sdf['filepath'])[0])\n",
    "\n",
    "            if channel == 'dapi':\n",
    "                if ii == 0:\n",
    "                    seg_name = 'seg_' + fname\n",
    "                    seg_dapi =  io.imread(os.path.join(seg_dapi_dir, seg_name))\n",
    "                    # get the nuclear mask and nuclear labels\n",
    "                    nuclear_mask, nuclear_labels = prune_and_label_dapi(seg_dapi, debris_size, erosion_radius)\n",
    "\n",
    "\n",
    "                    # get the big cells (to be split if it contains more than 1 cells)\n",
    "                    big_cells = obtain_big_cells(nuclear_labels, area_thresh, cir_thresh)\n",
    "\n",
    "                    # get the final labels after splitting the big cells\n",
    "                    final_labels_1 = obtain_final_labels_after_splitting_big_objects(nuclear_labels, big_cells, ero_rad, \n",
    "                                                                min_rem_area, min_area_to_keep_cell)\n",
    "\n",
    "                    nuc_mask = final_labels_1\n",
    "\n",
    "                    # dialte the nuclear mask to get back to right size\n",
    "                    temp_img = np.logical_or(binary_dilation(nuc_mask, disk(2)), binary_fill_holes(seg_dapi))\n",
    "\n",
    "                    # use watershed method with final_labels as markers to obtain labeled cell mask\n",
    "                    final_labels = watershed(temp_img, markers=final_labels_1, mask=temp_img)\n",
    "\n",
    "                    temp_dapis[fname] = (seg_dapi, final_labels)\n",
    "\n",
    "                    # nuclei not touching border\n",
    "                    non_border_labels = clear_border(final_labels)\n",
    "                    dil_seg_dapi = binary_dilation(nuc_mask, disk(100))\n",
    "                    seg_cyto = np.logical_xor (dil_seg_dapi, nuc_mask)\n",
    "                    nucloc=np.asarray(np.where((nuc_mask==1))).T\n",
    "                    noncyt=np.asarray(np.where((seg_cyto==0))).T\n",
    "                    \n",
    "                else:\n",
    "                    seg_dapi, final_labels = temp_dapis[fname]\n",
    "                    \n",
    "                    # nuclei not touching border\n",
    "                    non_border_labels = clear_border(final_labels)\n",
    "\n",
    "\n",
    "\n",
    "            elif channel == 'exon':\n",
    "                exon_image =  io.imread(os.path.join(fpath, fname))\n",
    "    #             exon_image = exon_image / np.median(exon_image)\n",
    "                seg_exon = exon_image > (threshold_otsu(exon_image))*(1 + room/100)\n",
    "                threshold['exon'][room]['time' +str(t)+'field'+str(f)]=(threshold_otsu(exon_image))*(1 + room/100)\n",
    "                \n",
    "            elif channel == 'intron':\n",
    "                \n",
    "                if ii == 0:\n",
    "                    intron_image = sitk.ReadImage(os.path.join(fpath, fname))\n",
    "                    gaussian_blur = sitk.SmoothingRecursiveGaussianImageFilter()\n",
    "                    gaussian_blur.SetSigma ( float ( sigma ) )\n",
    "                    blur_intron = gaussian_blur.Execute ( intron_image )\n",
    "\n",
    "                    max_entropy_filter = sitk.MaximumEntropyThresholdImageFilter()\n",
    "                    max_entropy_filter.SetInsideValue(0)\n",
    "                    max_entropy_filter.SetOutsideValue(1)\n",
    "                    seg = max_entropy_filter.Execute(blur_intron)\n",
    "                    seg_intron = sitk.GetArrayFromImage(seg)\n",
    "\n",
    "                    blur_intron_img = sitk.GetArrayFromImage(blur_intron)\n",
    "\n",
    "                    intron_threshold = np.min(blur_intron_img[np.where(seg_intron != 0)])\n",
    "\n",
    "                    temp_introns[fname] = (blur_intron_img, intron_threshold)\n",
    "\n",
    "                    seg_intron = blur_intron_img > intron_threshold\n",
    "                    threshold['intron'][room]['time' +str(t)+'field'+str(f)]=intron_threshold\n",
    "                    \n",
    "                else:\n",
    "                    blur_intron_img, intron_threshold = temp_introns[fname]\n",
    "                    seg_intron = blur_intron_img > (intron_threshold*(1 + room/100))\n",
    "                    threshold['intron'][room]['time' +str(t)+'field'+str(f)]=(intron_threshold*(1 + room/100))\n",
    "\n",
    "\n",
    "            else:\n",
    "                print('Different than dapi, exon or intron image found!')\n",
    "                \n",
    "        if room ==0:\n",
    "            comb_img = np.zeros((seg_exon.shape[0], seg_exon.shape[0],3))\n",
    "            comb_img[:,:,0] = seg_intron\n",
    "            comb_img[:,:,1] = seg_exon\n",
    "            comb_img[:,:,2] = nuc_mask\n",
    "            marked_img = mark_boundaries(comb_img, non_border_labels, color=(1, 1, 1), outline_color=(1, 1, 1))\n",
    "            io.imsave(os.path.join(seg_dir, 'combined_' + fname), np.uint8(marked_img*255))\n",
    "            \n",
    "        Mature['inside']['time' +str(t)+'field'+str(f)]=np.array([])\n",
    "        Mature['outside']['time' +str(t)+'field'+str(f)]=np.array([])\n",
    "        Mature['outside_area']['time' +str(t)+'field'+str(f)]=np.array([])\n",
    "        Mature['outside_mean_intensities']['time' +str(t)+'field'+str(f)]=np.array([])\n",
    "        Mature['outside_integ_intensities']['time' +str(t)+'field'+str(f)]=np.array([])\n",
    "        Mature['outside_integ_area']['time' +str(t)+'field'+str(f)]=np.array([])\n",
    "        Mature['inside_intensities']['time' +str(t)+'field'+str(f)]=np.array([])\n",
    "        Mature['coloc']['time' +str(t)+'field'+str(f)]=np.array([])\n",
    "\n",
    "        green=label(seg_exon)\n",
    "        red=label(seg_intron)\n",
    "        blue=label(non_border_labels)\n",
    "        \n",
    "        green2=label(seg_exon2)\n",
    "        \n",
    "        for exon2 in regionprops(green2,intensity_image=exon_image2):\n",
    "            Mature['outside']['time' +str(t)+'field'+str(f)]=np.append(Mature['outside']['time' +str(t)+'field'+str(f)],exon2.label)\n",
    "            Mature['outside_area']['time' +str(t)+'field'+str(f)]=np.append(Mature['outside_area']['time' +str(t)+'field'+str(f)],exon2.area)\n",
    "            Mature['outside_mean_intensities']['time' +str(t)+'field'+str(f)]=np.append(Mature['outside_mean_intensities']['time' +str(t)+'field'+str(f)],exon2.mean_intensity)\n",
    "            Mature['outside_integ_intensities']['time' +str(t)+'field'+str(f)]=np.append(Mature['outside_integ_intensities']['time' +str(t)+'field'+str(f)],sum(sum(exon2.intensity_image)))\n",
    "            Mature['outside_integ_area']['time' +str(t)+'field'+str(f)]=np.append(Mature['outside_integ_area']['time' +str(t)+'field'+str(f)],\\\n",
    "                                                                              [sum(sum(exon2.intensity_image)),exon2.area])\n",
    "    \n",
    "\n",
    "#         print(time()-t_time, 'seconds')\n",
    "        \n",
    "        # threshold values for different files with different elbow room allowed\n",
    "        threshold_df = threshold_df.append([{'filename': file_name,\n",
    "                                         'elbow_room': room,\n",
    "                                         'exon_thresh': (threshold_otsu(exon_image))*(1 + room/100),\n",
    "                                         'intron_thresh': (intron_threshold*(1 + room/100)),\n",
    "                                         'time': t,\n",
    "                                         'field' : f,\n",
    "                                     'rough_estimate_num_exons': np.max(green),\n",
    "                                     'rough_estimate_num_introns': np.max(red),\n",
    "                                          },])\n",
    "\n",
    "\n",
    "\n",
    "        summary['time' +str(t)+'field'+str(f)]={}\n",
    "\n",
    "        ### get measurements\n",
    "        # number of cells not toching border\n",
    "\n",
    "        for nuc in regionprops(blue):\n",
    "            nuc_id=nuc.label\n",
    "            summary['time' +str(t)+'field'+str(f)]['nuc'+str(nuc_id)]={}\n",
    "            summary['time' +str(t)+'field'+str(f)]['nuc'+str(nuc_id)]['intron']=[]\n",
    "\n",
    "            summary['time' +str(t)+'field'+str(f)]['nuc'+str(nuc_id)]['exon']=[]\n",
    "            summary['time' +str(t)+'field'+str(f)]['nuc'+str(nuc_id)]['nasexon']=[]\n",
    "\n",
    "            summary['time' +str(t)+'field'+str(f)]['nuc'+str(nuc_id)]['colocspot']=[]\n",
    "            summary['time' +str(t)+'field'+str(f)]['nuc'+str(nuc_id)]['colocspotarea']=[]\n",
    "            summary['time' +str(t)+'field'+str(f)]['nuc'+str(nuc_id)]['colocspotarea2']=[]\n",
    "            summary['time' +str(t)+'field'+str(f)]['nuc'+str(nuc_id)]['colocspotmi']=[]\n",
    "            summary['time' +str(t)+'field'+str(f)]['nuc'+str(nuc_id)]['colocspotcenter']=[]\n",
    "            summary['time' +str(t)+'field'+str(f)]['nuc'+str(nuc_id)]['distarea']=[]\n",
    "            summary['time' +str(t)+'field'+str(f)]['nuc'+str(nuc_id)]['Ncolocspot']=[]\n",
    "            summary['time' +str(t)+'field'+str(f)]['nuc'+str(nuc_id)]['coord_nas']=[]\n",
    "            summary['time' +str(t)+'field'+str(f)]['nuc'+str(nuc_id)]['nascent']=[]\n",
    "            summary['time' +str(t)+'field'+str(f)]['nuc'+str(nuc_id)]['Nnascent']=[]\n",
    "\n",
    "            summary['time' +str(t)+'field'+str(f)]['nuc'+str(nuc_id)]['maturein']=[]\n",
    "            summary['time' +str(t)+'field'+str(f)]['nuc'+str(nuc_id)]['integ_intens']=[]\n",
    "\n",
    "            for exon in regionprops(green,intensity_image=exon_image):\n",
    "                exon_id=exon.label\n",
    "                if exon.area<200:\n",
    "                    if (((exon.coords[:, None] == nuc.coords).all(-1).any(-1)==True).any()):\n",
    "                        summary['time' +str(t)+'field'+str(f)]['nuc'+str(nuc_id)]['exon'].append(exon_id)\n",
    "\n",
    "            for intron in regionprops(red,intensity_image=sitk.GetArrayFromImage(intron_image)):\n",
    "                intron_id=intron.label\n",
    "                if (((intron.coords[:, None] == nuc.coords).all(-1).any(-1)==True).all()):\n",
    "                    summary['time' +str(t)+'field'+str(f)]['nuc'+str(nuc_id)]['intron'].append(intron_id)         \n",
    "\n",
    "                    for nucexon in summary['time' +str(t)+'field'+str(f)]['nuc'+str(nuc_id)]['exon']:\n",
    "                        if (((intron.coords[:, None] == regionprops(green)[nucexon-1].coords).all(-1).any(-1)==True).any()):\n",
    "                            summary['time' +str(t)+'field'+str(f)]['nuc'+str(nuc_id)]['colocspot'].append([intron_id,nucexon])\n",
    "                            summary['time' +str(t)+'field'+str(f)]['nuc'+str(nuc_id)]['colocspotarea2'].append([regionprops(red)[intron_id-1].area,regionprops(green)[nucexon-1].area])\n",
    "                            summary['time' +str(t)+'field'+str(f)]['nuc'+str(nuc_id)]['colocspotmi'].append([regionprops(red,intensity_image=\\\n",
    "                                                                                                                     sitk.GetArrayFromImage(intron_image))[intron_id-1].mean_intensity,regionprops(green,intensity_image=exon_image)[nucexon-1].mean_intensity])\n",
    "                            summary['time' +str(t)+'field'+str(f)]['nuc'+str(nuc_id)]['distarea'].append([distance(nuc.centroid,regionprops(red)[intron_id-1].centroid),regionprops(red)[intron_id-1].area])\n",
    "                            summary['time' +str(t)+'field'+str(f)]['nuc'+str(nuc_id)]['integ_intens'].append(sum(sum(regionprops(green,intensity_image=exon_image)[nucexon-1].intensity_image)))\n",
    "                            summary['time' +str(t)+'field'+str(f)]['nuc'+str(nuc_id)]['nasexon'].append(np.sum(regionprops(green,intensity_image=exon_image)[nucexon-1].intensity_image))\n",
    "                        \n",
    "                            summary['time' +str(t)+'field'+str(f)]['nuc'+str(nuc_id)]['coord_nas'].append(regionprops(green)[nucexon-1].coords)\n",
    "                            summary['time' +str(t)+'field'+str(f)]['nuc'+str(nuc_id)]['colocspotcenter'].append([regionprops(red)[intron_id-1].centroid,regionprops(green)[nucexon-1].centroid])\n",
    "                            summary['time' +str(t)+'field'+str(f)]['nuc'+str(nuc_id)]['colocspotarea'].append(np.count_nonzero(((regionprops(red)[intron_id-1].coords[:, None]==regionprops(green)[nucexon-1].coords).all(-1).any(-1))==True))\n",
    "                            if ((np.count_nonzero(((regionprops(red)[intron_id-1].coords[:, None]==regionprops(green)[nucexon-1].coords).all(-1).any(-1))==True))<2):\n",
    "                                summary_warning['onepixel'].append([t,f,nuc_id,regionprops(red)[intron_id-1].centroid,regionprops(green)[nucexon-1].centroid])\n",
    "   \n",
    "\n",
    "            X=np.array(summary['time' +str(t)+'field'+str(f)]['nuc'+str(nuc_id)]['colocspot'])\n",
    "            W= np.array(summary['time' +str(t)+'field'+str(f)]['nuc'+str(nuc_id)]['intron'])\n",
    "            Y=np.array(summary['time' +str(t)+'field'+str(f)]['nuc'+str(nuc_id)]['exon'])\n",
    "\n",
    "            if(len(X)>0):\n",
    "                summary['time' +str(t)+'field'+str(f)]['nuc'+str(nuc_id)]['maturein']=np.setdiff1d(Y,X[:,1])\n",
    "                if((len(X[:,0])>len(np.unique(X[:,0]))) or(len(X[:,1])>len(np.unique(X[:,1])))) :\n",
    "                    unique, counts = np.unique(X[:,0], return_counts=True)\n",
    "                    unique2, counts2 = np.unique(X[:,1], return_counts=True)\n",
    "                    if((len(X[:,0])>len(np.unique(X[:,0])))):\n",
    "                        for i in (unique[(counts)>1]):\n",
    "                            summary['time' +str(t)+'field'+str(f)]['nuc'+str(nuc_id)]['nascent'].append([i,X[X[:,0]==i][:,1]])\n",
    "\n",
    "                        v=([X[X[:,0]==i][0][0] for i in unique[(counts)==1]])\n",
    "                        u=([X[X[:,0]==i][0][1] for i in unique[(counts)==1]])\n",
    "                        r=([X[X[:,0]==i][0] for i in unique[(counts)==1]])\n",
    "                        if (len(u)>len(np.unique(u))):\n",
    "                            for j in np.unique(u):\n",
    "                                summary['time' +str(t)+'field'+str(f)]['nuc'+str(nuc_id)]['nascent'].append([X[X[:,1]==j][:,0],j])\n",
    "                        elif(len(r)>0):\n",
    "                            summary['time' +str(t)+'field'+str(f)]['nuc'+str(nuc_id)]['nascent']=np.vstack((summary['time' +str(t)+'field'+str(f)]['nuc'+str(nuc_id)]['nascent'],r))\n",
    "\n",
    "                    else:\n",
    "                        for k in (unique2):\n",
    "\n",
    "                            summary_warning['Warningex'].append([t,f,nuc_id,regionprops(green)[k-1].centroid])\n",
    "                            summary['time' +str(t)+'field'+str(f)]['nuc'+str(nuc_id)]['nascent'].append([X[X[:,1]==k][:,0],k]) \n",
    "                else:\n",
    "                    summary['time' +str(t)+'field'+str(f)]['nuc'+str(nuc_id)]['nascent']=summary['time' +str(t)+'field'+str(f)]['nuc'+str(nuc_id)]['colocspot']\n",
    "            else:\n",
    "                summary['time' +str(t)+'field'+str(f)]['nuc'+str(nuc_id)]['maturein']=summary['time' +str(t)+'field'+str(f)]['nuc'+str(nuc_id)]['exon']\n",
    "\n",
    "            summary['time' +str(t)+'field'+str(f)]['nuc'+str(nuc_id)]['Ncolocspot']=len(summary['time' +str(t)+'field'+str(f)]['nuc'+str(nuc_id)]['colocspot'])\n",
    "            summary['time' +str(t)+'field'+str(f)]['nuc'+str(nuc_id)]['Nnascent']=len(summary['time' +str(t)+'field'+str(f)]['nuc'+str(nuc_id)]['nascent'])\n",
    "\n",
    "   \n",
    "        print('t = ' ,t,'min, f = ',f,\", \", time()-starting_time, 'seconds')\n",
    "        \n",
    "    with open(os.path.join(seg_dir, 'summaryJan2FVWAE2' + append_name + '.pickle'), 'wb') as handle:\n",
    "        pickle.dump(summary, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "    with open(os.path.join(seg_dir, 'MatureJan2FVWAE2' + append_name + '.pickle'), 'wb') as handle:\n",
    "        pickle.dump(Mature, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "    \n",
    "    print('Elbow room (in %) = ' , room, ', total time taken :',  time()-starting_time, 'seconds')\n",
    "        \n",
    "threshold_df = threshold_df.reset_index(drop=True)\n",
    "\n",
    "with open(os.path.join(seg_dir, 'thresholdFVWAE2.pickle'), 'wb') as handle:\n",
    "        pickle.dump(threshold, handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
